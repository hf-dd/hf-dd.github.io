<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HF Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-09-17T02:10:42.175Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>HF</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Sping Cloud生态的各个组件！</title>
    <link href="http://yoursite.com/2020/09/17/Sping-Cloud%E7%94%9F%E6%80%81%E7%9A%84%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%EF%BC%81/"/>
    <id>http://yoursite.com/2020/09/17/Sping-Cloud%E7%94%9F%E6%80%81%E7%9A%84%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%EF%BC%81/</id>
    <published>2020-09-17T01:44:57.000Z</published>
    <updated>2020-09-17T02:10:42.175Z</updated>
    
    <content type="html"><![CDATA[<p>引言：部门最近接收了一个新的大型项目的需求，该项目大量地方使用到了Spring Cloud技术，老大为了让我们在新需求正式开工之前学会使用Spring Cloud技术，要求我们每天写一篇关于该技术各个组件的学习记录，而我同时也会写入到我的博客中，大家一起学习！</p>]]></content>
    
    <summary type="html">
    
      关于Spring Cloud组件的一些学习内容
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>动态代理JDK和cglib</title>
    <link href="http://yoursite.com/2020/02/21/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86JDK%E5%92%8Ccglib/"/>
    <id>http://yoursite.com/2020/02/21/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86JDK%E5%92%8Ccglib/</id>
    <published>2020-02-21T03:44:03.000Z</published>
    <updated>2020-02-22T02:47:23.884Z</updated>
    
    <content type="html"><![CDATA[<h3 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a><strong>代理模式</strong></h3><p>代理类与委托类具有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等，代理类本身并不是真正的提供服务，他只是通过调用委托类的方法去实现接口的方法，可以增强委托类的功能，在其前后做一些事情。</p><h3 id="静态代理"><a href="#静态代理" class="headerlink" title="静态代理"></a><strong>静态代理</strong></h3><p>首先业务实现类，业务代理类都实现同一个业务接口，业务实现类负责具体业务，业务代理类负责对调用的业务方法做拦截、过滤等功能。</p><p>缺点：很明显，一个代理类只能对一个业务接口的实现类进行包装，而且如果方法的处理代码一样，就需要重复写很多遍。这时，我们可以定义这样一个代理类，根据传进来的业务实现类和方法名进行具体调用——那就是动态代理。</p><h3 id="动态代理"><a href="#动态代理" class="headerlink" title="动态代理"></a>动态代理</h3><p><strong>JDK动态代理</strong></p><p>首先业务实现类实现业务接口，再新建一个代理类并实现<strong>InvocationHandler</strong>接口。                            首先重写InvocationHandler接口中的<strong>invoke</strong>方法<strong>对业务类进行前后处理</strong>，里面有三个参数    <strong>proxy</strong>：被代理的对象。<strong>method</strong>：调用的方法            <strong>args</strong>：调用的方法的参数。</p><p>然后再实现<strong>Proxy类的newProxyInstance</strong>方法：里面有三个参数        ClassLoader   loader:类加载器        interfaces:所有接口        InvocationHandler  h:得InvocationHandler接口的子类实例     <strong>返回的对象便是我们要的代理对象。</strong></p><p>动态代理类的字节码在程序运行时由Java反射机制动态生成，无需程序员手工编写它的源代码</p><p><strong>cglib动态代理</strong></p><p>JDK的代理是实现了接口，而cglib代理则是通过继承来实现的，代理类继承业务实现类，重写父类方法，并且该代理类不需要接口，只需要传入一个类就可以生成一个代理类并处理，而JDK需要传入接口就是上文的<strong>interfaces接口</strong>。</p><p>原理：继承父类的代理类实现了一个接口MethodInterceptor，里面有一个<strong>intercept</strong>方法用来重写父类方法，它有四个参数，代理类本身，拦截的方法，参数，cglib方法。返回的是cglib方法的<strong>invokeSuper</strong>方法，这是因为cglib采用了fastclass机制，避开调不到父类方法的问题，还加速了方法的调用。原理就是给每个方法加编号，通过方法执行。</p><p>为什么返回cglib方法，不返回拦截的方法（父类的方法），因为子类重写了父类方法，根据多态我们知道我们是调用不到父类的方法的，所以不返回拦截方法。</p><p><strong>总结</strong></p><p>cglib返回的代理对象是目标对象的子类。而jdk产生的代理对象和目标对象都实现了一个公共接口。</p><p>jdk创建对象的速度远大于cglib，这是由于cglib创建对象时需要操作字节码。cglib执行速度略大于jdk，所以比较适合单例模式。</p><p>cglib的大部分类是直接对Java字节码进行操作，这样生成的类会在Java的永久堆中。如果动态代理操作过多,OOM.</p><p>spring默认使用jdk动态代理，&lt;aop:aspectj-autoproxy proxy-target-class=”true”/&gt;设置cglib动态代理。</p>]]></content>
    
    <summary type="html">
    
      AOP采用的俩种代理模式！
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Redis的9种数据结构</title>
    <link href="http://yoursite.com/2020/02/12/Redis%E7%9A%849%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>http://yoursite.com/2020/02/12/Redis%E7%9A%849%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2020-02-12T12:56:07.000Z</published>
    <updated>2020-02-17T05:37:47.871Z</updated>
    
    <content type="html"><![CDATA[<p>我们都知道Redis常用的数据结构有五种分别为String，hash，set，list，zset。</p><p>特殊的数据结构有四种：bitmap，hyperLogLog，bloomFilter，GeoHash 。</p><p>虽然大家都也听说过，今天就来总结一下吧，毕竟Redis非常重要！</p><p>先大致写一下常用的：</p><p><strong>String</strong></p><p>String类型是 Redis中最常使用的类型，内部的实现是通过 SDS来存储的。SDS 类似于 <strong>Java</strong> 中的 <strong>ArrayList</strong>，它可以存储任意二进制数据，可以通过预分配冗余空间的方式来减少内存的频繁分配。    <strong>用处</strong>：普通的get,set方法KV操作，常规。</p><p><strong>Hash</strong></p><p>类似Map的一种结构。    <strong>用处</strong>：可以存入结构化数据，例如往缓存存一个对象，可以方便的操作其中的某个字段。</p><p><strong>List</strong></p><p><strong>用处</strong>：使用List(有序链表)的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令（返回列表指定区间的元素），做基于redis的分页功能，性能极佳。</p><p><strong>Set</strong></p><p>Set 是无序集合，很明显的一个作用就是去重，不用多说。</p><h4 id="Sorted-Set（zset）"><a href="#Sorted-Set（zset）" class="headerlink" title="Sorted Set（zset）"></a>Sorted Set（zset）</h4><p>排好序的Set，底层实现<strong>跳表</strong>，多了一个权重参数score分数，写进去自动根据分数排序。</p><p>用处：排行榜应用之类的，用Sorted Sets来做带权重的队列。</p><p>接下来就是不常用的奥。</p><p><strong>Bitmap</strong></p><p>位图，字符串一个字符是8个比特， bitmap 底层就是 string， <strong>用处</strong>：例如计算一个用户在指定时间内签到的次数，8位，1位表示一天，0表示未签到，1表示签到。</p><p><strong>HyperLogLog</strong></p><p>提供不精确的去重计数，小规模使用set去重，那要是访问量巨大呢？HyperLogLog就出现了，优势就是只占用 12KB 的内存。</p><p><strong>GeoHash</strong></p><p>可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。常用来计算 附近的人，附近的商店。</p><p><strong>BloomFilter</strong></p><p>他叫布隆，没错就是那个布隆，布隆过滤器。我第一次听说他的作用就是<strong>防止缓存穿透</strong>，利用高效算法来判断某个值是否存在。                        <strong>用处</strong>：垃圾邮件过滤，缓存穿透</p><p><strong>原理：</strong>当我们向 BloomFilter  添加数据的时候，它首先会将我们的数据(key)做几次hash运算，每个hash运算都会得到一个不用的位数组索引下标，此时我们就将算出的几个下标的位置的值改成1就行（就是放入bitmap中）。如果判断元素是否存在，只要  判断所在的所有索引下标的值都是1 就行了。</p><p>很明显有一个问题，下标重复了咋办，没办法，这就是误差，所以说，<strong>没有的肯定没有，有的也不一定有</strong>。</p>]]></content>
    
    <summary type="html">
    
      Redis可不是只有五种数据结构奥！
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Redis持久化机制rdb和aof</title>
    <link href="http://yoursite.com/2020/02/12/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6rdb%E5%92%8Caof/"/>
    <id>http://yoursite.com/2020/02/12/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6rdb%E5%92%8Caof/</id>
    <published>2020-02-12T06:13:57.000Z</published>
    <updated>2020-03-31T14:04:21.716Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Redis</strong> 提供了 RDB 和 AOF 两种持久化方式</p><p><strong>RDB：</strong>对 <strong>Redis</strong> 中的数据执行<strong>周期性</strong>的持久化，即按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件，对应产生的数据文件为dump.rdb。</p><p><strong>AOF:AOF</strong> 机制对每条写入命令作为日志，以 <strong>append-only</strong> 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快。当Redis重启是会通过重新执行文件中保存的<strong>写命令</strong>来在内存中重建整个数据库的内容。</p><p><strong>Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。</strong></p><p>RDB：</p><p>优点：<strong>RDB</strong>对<strong>Redis</strong>的性能影响非常小，是因为在同步数据的时候他只是<strong>fork</strong>了一个子进程去做持久化的，而且他在数据恢复的时候速度比<strong>AOF</strong>来的快。</p><p>缺点：<strong>RDB</strong>都是快照文件，都是默认五分钟才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。</p><p>AOF：</p><p>优点：<strong>AOF</strong>是一秒一次同步，最多丢一秒数据。因为是只追加的方式写数据，所以不用寻址，性能惊人。<strong>AOF</strong>的日志是通过一个叫<strong>非常可读</strong>的方式记录的，适合做数据紧急恢复。采用“<strong>重放</strong>”机制以恢复到 Redis关闭前的最后时刻。</p><p>缺点：一样的数据，<strong>AOF</strong>文件比<strong>RDB</strong>还要大。<strong>AOF</strong>开启后Redis性能低，因为要异步刷新日志。</p><p><strong>如何选择：</strong></p><p>俩者结合使用，如果真一下丢失了许多数据，<strong>第一时间用RDB恢复，再用AOF恢复</strong>，因为RDB恢复数据快，但是不全，所以再让AOF来补全，完美！</p>]]></content>
    
    <summary type="html">
    
      Redis持久化机制rdb和aof俩种机制的区别讲解
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>select、poll、epoll的区别</title>
    <link href="http://yoursite.com/2020/02/11/select%E3%80%81poll%E3%80%81epoll%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2020/02/11/select%E3%80%81poll%E3%80%81epoll%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-02-11T05:41:47.000Z</published>
    <updated>2020-02-23T14:01:15.744Z</updated>
    
    <content type="html"><![CDATA[<h4 id="概述："><a href="#概述：" class="headerlink" title="概述："></a>概述：</h4><p><strong>多路I/O复用模型</strong>是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件发生时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流。</p><p><strong>epoll</strong> 是只轮询那些真正发出了事件的流，并且会按顺序的处理就绪的流，避免了大量的无用操作，高效的用一个线程处理了多个请求。</p><p><strong>select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的</strong>，而异步I/O则无需自己负责进行读写。</p><h4 id="select："><a href="#select：" class="headerlink" title="select："></a>select：</h4><p>select本质上是通过设置或者<strong>检查</strong>存放fd标志位的数据结构来进行下一步处理，就是说用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态.</p><p>什么是fd:文件描述符,进程中具体某个文件信息在文件表中的索引位置.</p><p>缺点：1.单个进程可监视的fd数量有限制，在Linux上一般为1024</p><p>2.采用轮询的方法进行扫描，效率较低</p><p>3.需要维护一个用来存放大量fd的数据结构</p><h4 id="poll"><a href="#poll" class="headerlink" title="poll:"></a>poll:</h4><p>poll本质上和select没有区别，只不过它没有最大连接数的限制，原因是它基于链表的。</p><p>poll和select共有的缺点就是，1.包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。</p><p>2.select()和poll()将就绪的文件描述符告诉进程后，如果进程没有对其进行IO操作，那么下次调用select()和poll()的时候将再次报告这些文件描述符，所以它们一般不会丢失就绪的消息，这种方式称为<strong>水平触发</strong>。</p><h4 id="epoll："><a href="#epoll：" class="headerlink" title="epoll："></a><strong>epoll：</strong></h4><p><strong>对比pool和select来讲就是当有数据就绪的时候，不用去遍历所有的文件描述符。直接取就绪的文件描述符。</strong></p><p><strong>epoll可以同时支持水平触发和边缘触发</strong>，边缘触发：只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发，性能更高，代码复杂。</p><p>epoll是基于事件驱动的，事先先注册一个文件标识符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。</p><p>调用epoll_wait()得到的不是真正的就绪文件描述符，而是一个代表就绪描述符数量的值，使用了内存映射（mmap）技术，省掉了这些文件描述符在系统调用时复制的开销。</p><p><strong>epoll工作原理</strong></p><p>mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址（不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理地址），使得这块物理内存对内核和对用户均可见，减少用户态和内核态之间的数据交换。内核可以直接看到epoll监听的句柄，效率高。</p><p>epoll在实现上采用红黑树去存储所有套接字，当添加或者删除一个套接字时（epoll_ctl），都在红黑树上去处理，红黑树本身插入和删除性能比较好，时间复杂度O(logN)。</p><p>这个回调函数其实就所把这个事件添加到rdllist这个双向链表中。一旦有事件发生，epoll就会将该事件添加到双向链表中。    那么当我们调用epoll_wait时，epoll_wait只需要检查rdlist双向链表中是否有存在注册的事件，效率非常可观。</p>]]></content>
    
    <summary type="html">
    
      多路I/O复用模型select、poll、epoll概念理解加区别
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>String,StringBuffer,StringBuilder</title>
    <link href="http://yoursite.com/2020/02/10/String-StringBuffer-StringBuilder/"/>
    <id>http://yoursite.com/2020/02/10/String-StringBuffer-StringBuilder/</id>
    <published>2020-02-10T15:12:20.000Z</published>
    <updated>2020-07-13T13:15:28.957Z</updated>
    
    <content type="html"><![CDATA[<p>首先我们知道String 是被声明为 final class，是不可变字符串。因为它的不可变性，所以拼接字符串时候会产生很多无用的中间对象，如果频繁的进行这样的操作对性能有所影响。</p><p>所以StringBuffer  StringBuilder就出现了。</p><p>StringBuffer、StringBuilder、String 中都实现了 CharSequence 接口。CharSequence 是一个定义字符串操作的接口，它只包括 length()、charAt(int index)、subSequence(int start, int end) 这几个 API。</p><p>String是直接实现<strong>CharSequence</strong> 接口的，而StringBuffer、StringBuilder不一样，他们是先都继承了同一个类<strong>AbstractStringBuilder</strong>再实现了<strong>Serializable</strong>序列化接口，<strong>CharSequence</strong>接口以及<strong>Appendabe</strong>接口。</p><p>StringBuilder通过length()和capacity()来获取对应的总容量和已经使用的容量，初始容量为16个字符，如果使用append()方法在字符串后面追加东西的时候，会调用<strong>ensureCapacityInternal</strong> 这个方法判断是否需要扩容，需要就调用<strong>newCapacity</strong>方法进行扩容：<strong>构建新的存储空间更大的字符串，将旧的复制过去</strong>，<strong>扩容大小2倍+2</strong> 。</p><p>StringBuffer也是继承AbstractStringBuilder的，只是其在重写父类的方法的时候加上了synchronized关键字，使得StringBuffer的方法变成了线程安全的方法。通俗讲就是加了锁的StringBuilder，速度当然会降下来。</p>]]></content>
    
    <summary type="html">
    
      String,StringBuffer,StringBuilder的区别和原理实现
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>三大范式通俗理解</title>
    <link href="http://yoursite.com/2020/02/09/%E4%B8%89%E5%A4%A7%E8%8C%83%E5%BC%8F%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/02/09/%E4%B8%89%E5%A4%A7%E8%8C%83%E5%BC%8F%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3/</id>
    <published>2020-02-09T03:45:34.000Z</published>
    <updated>2020-02-09T03:58:57.734Z</updated>
    
    <content type="html"><![CDATA[<p><strong>第一范式（1NF）：要求数据库表的每一列都是不可分割的原子数据项</strong></p><p>例如：数据库有一个列，为家庭信息，里面却存入了人口和地址俩个信息，故不满足第一范式。</p><p>修改：应该将家庭信息分成家庭人口和家庭住址俩列，就可以满足了。</p><p><strong>第二范式（2NF）：在1NF基础上消除非主属性对主码的部分函数依赖</strong></p><p>例如：有一个数据库表存在<strong>联合主键</strong>（订单号和产品号），但存在一个订单价格只与订单号有关，而与产品号无关，此时就不满足第二范式了。</p><p>修改：分成俩个表，将订单价格与订单号单独再放入另一个表中。</p><p><strong>第三范式（3NF）：在2NF基础上消除传递依赖</strong></p><p>第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。</p><p>例如：所有属性完全依赖学号，满足第二范式，但学生性别和学生年龄都直接依赖于学生姓名，不满足第三范式</p><p>修改：分成俩个表，将学生姓名，性别和年龄再单独放入另一个表。</p>]]></content>
    
    <summary type="html">
    
      三大范式通俗理解与举例
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>HTTP</title>
    <link href="http://yoursite.com/2020/02/08/HTTP/"/>
    <id>http://yoursite.com/2020/02/08/HTTP/</id>
    <published>2020-02-08T07:12:00.000Z</published>
    <updated>2020-03-27T13:54:18.960Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><p>http是一个基于TCP/IP协议的无状态，无连接的超文本传输协议。</p><p>无连接：每次连接只处理一个请求，处理完收到客户应答后就断开连接（就是短连接）。</p><p>无状态：对于事务处理没有记忆能力。意味着如果后续处理需要前面的信息，则它必须重传，导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。</p><p>HTTP请求报文由3部分组成（<strong>请求行+请求头+请求体</strong>）：</p><p>请求行：1.请求方法，常用get,post以及delete，head,put等等    2.URL地址        3.协议和版本号</p><p>请求头：有若干属性，<strong>Accept</strong>:告诉服务端 客户端接受什么类型的响应                <strong>cookie:</strong>里面的jsessionid值用来session区分用    <strong>Referer</strong>：区分URL来源        <strong>Cache-Control</strong>：控制要不要存入缓存</p><p>提高HTTP连接性能的四个方法： <strong>并行连接</strong>，通过多条TCP连接发起并发的HTTP请求     </p><p><strong>持久连接</strong>，重用TCP连接，以消除连接及关闭的时延     </p><p><strong>管道化连接</strong>， 通过共享的TCP连接发起并发的HTTP请求        </p><p><strong>复用连接</strong>，交替传送请求和相应报文（实验阶段）</p><h3 id="如何正确的关闭HTTP连接？"><a href="#如何正确的关闭HTTP连接？" class="headerlink" title="如何正确的关闭HTTP连接？"></a><strong>如何正确的关闭HTTP连接？</strong></h3><p>Client先关闭自己的输出信道（Client不能把自己的输入信道关闭了）。</p><p>然后Client周期性地轮询自己的输入信道的状态（比如，读取数据时，是不是 已经读到的流的结尾了），如果读到了流的结束标识符，那意味着Server发过来的数据都已经收到了。</p><p>总之，对于HTTP连接的双方而言，当不再需要传输数据时，<strong>双方都先把自己的输出信道关闭了</strong>，<strong>然后读取输入信道中的流</strong>，如果读到了末尾(比如流结束符返回-1)，那么就可以<strong>正常关闭</strong>HTTP连接了。</p>]]></content>
    
    <summary type="html">
    
      HTTP请求报文和优化
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>LongAdder的原理和优势</title>
    <link href="http://yoursite.com/2020/02/07/LongAdder%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E4%BC%98%E5%8A%BF/"/>
    <id>http://yoursite.com/2020/02/07/LongAdder%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E4%BC%98%E5%8A%BF/</id>
    <published>2020-02-07T08:46:36.000Z</published>
    <updated>2020-02-11T05:30:04.534Z</updated>
    
    <content type="html"><![CDATA[<h3 id="LongAdder"><a href="#LongAdder" class="headerlink" title="LongAdder"></a>LongAdder</h3><p>在原来处理高并发的计数时，一直采用的AtomicLong方法，利用的是CAS机制，实现原子操作。而在JDK1.8引入了LongAdder之后，我们推荐优先LongAdder，而不是AtomicLong这是为什么呢？</p><h4 id="CAS（无锁化机制）"><a href="#CAS（无锁化机制）" class="headerlink" title="CAS（无锁化机制）:"></a>CAS（无锁化机制）:</h4><p>实现多线程同步的原子指令！</p><p>CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。缺点，解决不了ABA问题和多线程下无限自旋问题。</p><p>ABA：线程1对值为A的value正在进行操作，但是，线程2这时进来，将value改为B，并在线程1结束之前，又将value改为了A。此时线程1再进CAS操作的时候，A值虽然不变，但已经不是同一个值了。<strong>解决方法加一个版本控制</strong>，每次有线程修改了引用的值，就会进行版本的更新，每次比较连版本都比较上，Java 中提供了 AtomicStampedReference 这个类。</p><p>无限自旋：CAS机制就是，在一个死循环内，不断尝试修改目标值，直到修改成功。如果竞争不激烈，那么修改成功的概率就很高，可如果很激烈，那么失败的概率就会很高。失败的概率越高，自旋的次数就会越多，性能就会下降。</p><p>而LongAdder采用的是ConcurrentHashMap的实现思想，是对传统AtomicInteger等原子类的改进，将AtomicInteger的内部核心数据value分离成一个数组，每个线程访问时，通过哈希算法映射到其中一个数字进行计数，最后将这些和累加起来。其实就是<strong>将热点数据分离成多个单元</strong>，不同线程在自己的单元上计数，减少了线程竞争，提高了并发效率，本质上是用空间换时间的思想。</p>]]></content>
    
    <summary type="html">
    
      JDK1.8引入了LongAdder类，基本代替了AtomicLong，为什么?
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>HTTP1和2的变化</title>
    <link href="http://yoursite.com/2020/02/07/HTTP1%E5%92%8C2%E7%9A%84%E5%8F%98%E5%8C%96/"/>
    <id>http://yoursite.com/2020/02/07/HTTP1%E5%92%8C2%E7%9A%84%E5%8F%98%E5%8C%96/</id>
    <published>2020-02-07T05:34:19.000Z</published>
    <updated>2020-03-01T13:48:43.318Z</updated>
    
    <content type="html"><![CDATA[<h4 id="HTTP1-0"><a href="#HTTP1-0" class="headerlink" title="HTTP1.0"></a><strong>HTTP1.0</strong></h4><p>很早的版本，那时候只有一些简单网页传输和请求，所以性能一般。</p><p>默认是短连接的（每次通信都重新建立连接，非常消耗性能），可以通过keep-alive参数来建立一个长连接。</p><h5 id="HTTP1-1"><a href="#HTTP1-1" class="headerlink" title="HTTP1.1"></a><strong>HTTP1.1</strong></h5><p><strong>默认长连接</strong>（持久连接），可以在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。</p><p><strong>节约了带宽</strong>：HTTP 1.1支持只发送header信息(不带任何body信息)，而1.0会传送整个对象。并且HTTP1.1还支持<strong>断点传送</strong>，把文件分成几部分，一部分一部分传都可以。</p><p><strong>host域</strong>：1.0的时候，认为每台服务器都有一个唯一的IP地址。而在1.1的时候，服务器里面可以有多个虚拟主机，大家共用一个ip地址和端口。请求消息没有的host域的时候，会报400的错误。</p><p><strong>缓存：</strong>：增加了缓存处理，新字段如cache-control。</p><p><strong>错误通知：</strong>新增24个，如409表示请求的资源与资源的当前状态发生冲突，410表示服务器上的某个资源被永久性的删除。</p><p><strong>基于文本协议格式。</strong></p><h4 id="http2-0"><a href="#http2-0" class="headerlink" title="http2.0"></a>http2.0</h4><p><strong>采用新的二进制格式</strong>，方便且健壮。</p><p><strong>多路复用</strong>：同一个连接并发处理多个请求，性能非常高，原理是在每个请求上加一个ID，接收方是根据ID来识别请求。</p><p><strong>header压缩：</strong>在HTTP1.1中，HTTP请求和响应都是由请求行，请求头，请求体三部分组成。请求头内容非常多，每次重复传送，浪费资源。</p><p>2.0的时候，使用encoder来减少需要传输的header大小，通讯双方各自复制一份header fields表，避免重复传输header。</p><p><strong>服务端推送</strong>：客户端发起请求的时候，服务器端可以主动发送一些客户端没要求要的数据，例如一些静态资源.js之类的。</p>]]></content>
    
    <summary type="html">
    
      HTTP1.0，1.1和2.0各阶段的变化
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>线程池</title>
    <link href="http://yoursite.com/2020/02/07/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <id>http://yoursite.com/2020/02/07/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</id>
    <published>2020-02-07T04:55:25.000Z</published>
    <updated>2020-04-21T15:19:24.526Z</updated>
    
    <content type="html"><![CDATA[<h4 id="为什么会有线程池？"><a href="#为什么会有线程池？" class="headerlink" title="为什么会有线程池？"></a>为什么会有线程池？</h4><p>在Java中，我们一般通过集成Thread类和实现Runnnable接口，调用线程的start()方法实现线程的启动。但如果并发的数量很多，而且每个线程都是执行很短的时间便结束了，那样频繁的创建线程和销毁进程会大大的降低系统运行的效率。线程池正是<strong>为了解决多线程效率低的问题</strong>而产生的，他使得<strong>线程可以被复用</strong>，就是线程执行结束后不被销毁，而是可以继续执行其他任务。</p><p><strong>常见的几种线程池</strong></p><p>1.<strong>newSingleThreadExecutor</strong>：创建一个单线程的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)；</p><p>2.<strong>newFixedThreadPoo</strong>l：创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。</p><p>3.<strong>newCachedThreadPool</strong>：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。</p><p>4.<strong>newScheduledThreadPool</strong>：创建一个定长线程池，支持定时及周期性任务执行。</p><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p><strong>corePoolSize</strong> ：核心线程数。线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会 被销毁，除非设置了allowCoreThreadTimeOut。这里的最小线程数量即是corePoolSize。</p><p><strong>maximumPoolSize</strong> ：最大线程数，线程中最多能够创建的线程数量。什么时候会创建：当线程数大于等于核心线程数，且任务队列已满</p><p><strong>keepAliveTime</strong> ：空闲的线程保留的时间。</p><p><strong>TimeUnit</strong>：空闲线程的保留时间单位。</p><p><strong>workQueue</strong> 工作队列：当线程数大于等于核心线程数，且任务队列未满时，会先进入到此工作队列中，任务调度时再从队列中取出任务。</p><p>jdk中提供了四种<strong>工作队列queueCapacity</strong>    1.ArrayBlockingQueue基于数组的有界阻塞队列，按FIFO排序。    2.LinkedBlockingQuene基于链表的无界阻塞队列（其实最大容量为Integer.MAX），按照FIFO排序    3.SynchronousQuene一个不存储元素的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务，否则阻塞。    4.PriorityBlockingQueue具有优先级的无界阻塞队列。</p><p><strong>threadFactory</strong> 线程工厂</p><p><strong>handler</strong> 拒绝策略：当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这时如果有新任务提交进来，会执行拒绝策略。</p>]]></content>
    
    <summary type="html">
    
      线程池的作用以及常见参数
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>innodb 与 myisam 区别</title>
    <link href="http://yoursite.com/2020/02/06/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2020/02/06/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E5%8C%BA%E5%88%AB/</id>
    <published>2020-02-06T05:23:38.000Z</published>
    <updated>2020-02-14T14:19:41.585Z</updated>
    
    <content type="html"><![CDATA[<h4 id="主要区别："><a href="#主要区别：" class="headerlink" title="主要区别："></a>主要区别：</h4><p>1.InnoDB 支持事务，MyISAM 不支持，对于 InnoDB 每一条 SQL 语言都默认封装成事务， 自动提交，这样会影响速度，所以最好把多条 SQL 语言放在 开启事务begin transaction 和 提交commit之间，组成一个事务； </p><p>2.InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为MYISAM会失败；</p><p>3.InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引 效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此， 主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 </p><p>4.InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；</p><p>5.5.6之前Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高。MySql5.6版本后都支持全文索引了</p><p>6.MyISAM只支持表锁（数量大，并发量高，性能不行），InnoDB可以支持行锁（数量大，并发量高，性能优秀）。不命中索引，InnoDB也不能用行锁</p><h4 id="应用场景："><a href="#应用场景：" class="headerlink" title="应用场景："></a>应用场景：</h4><p>1.看是否支持事务，支持就选择 innodb，如果不需要可以考虑 MyISAM</p><p>2.如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读写也挺频繁，请使 用 InnoDB。 </p><p>3.系统崩溃，MyISAM 恢复起来更困难</p><p>4.MySQL5.5 版本开始 Innodb 已经成为 Mysql 的默认引擎(之前是 MyISAM)，说明其优势 是有目共睹的，如果你不知道用什么，那就用 InnoDB，至少不会差。</p>]]></content>
    
    <summary type="html">
    
      两种数据库引擎的区别
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>面经知识点概述总结！</title>
    <link href="http://yoursite.com/2020/02/05/%E9%9D%A2%E7%BB%8F%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2020/02/05/%E9%9D%A2%E7%BB%8F%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86/</id>
    <published>2020-02-05T13:24:05.000Z</published>
    <updated>2020-04-28T05:02:01.661Z</updated>
    
    <content type="html"><![CDATA[<p><strong>LRU：双向链表+hashMap</strong><br>save(key, value)，在 HashMap 找到 Key 对应的节点，如果节点存在，把这个节点移动队头。如果不存在，需要构造新的节点，并且尝试把节点塞到队头，如果LRU空间不足，则通过 tail 淘汰掉队尾的节点，同时在 HashMap 中移除 Key。get(key)，通过 HashMap 找到 LRU 链表节点，把节点放入表头</p><p><strong>逃逸分析（并不成熟</strong>）：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。<br>同步省略：同步块所使用的锁对象通过这种分析被证实只能够被一个线程访问，那么对对象的加的锁JIT编译阶段就会被优化掉（锁消除）<br>标量替换：在JIT阶段，如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆解成若干个其中包含的若干个成员变量来代替<br>栈上分配：经过逃逸分析后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配</p><p><strong>分布式锁：</strong><br>基于数据库（唯一索引）：唯一索引天然具有排他性，同一时刻只能允许一个竞争者获取锁<br>基于缓存：利用Redis的setnx key value这个命令，只有当key不存在时才会执行成功，如果key已经存在则命令执行失败。<br>基于Zookeeper：我们在Zookeeper中创建瞬时节点，利用节点不能重复创建的特性来保证排他性。</p><p>操作系统：内核、驱动程序、接口库、外围<br>Linux系统一般有4个主要部分:内核、shell、文件系统和应用程序。</p><p><strong>内存泄露</strong>：不再会被使用的对象的内存不能被回收，就是内存泄露。如果长生命周期的对象持有短生命周期的引用，就很可能会出现内存泄露。典型例子：<br>1 Vector v = new Vector(10);    //最简单的方法就是将 Vector 对象设置为 null。<br>2 for (int i = 1; i &lt; 100; i++) {<br>3     Object o = new Object();<br>4     v.add(o);      //循环申请Object对象，并将所申请的对象放入一个 Vector 中<br>5     o = null;  //仅仅释放引用本身，那么 Vector 仍然引用该对象，gc不可回收<br>6 }</p><p><strong>Redis为什么单线程还那么快</strong>：1.纯内存访问，Redis将所有数据放在内存中<br>2.非阻塞I/O,Redis使用I/O多路复用技术，以让单个线程高效的处理多个连接请求                                                  3.单线程避免了线程切换和竞争产生的消耗</p><p><strong>为什么zset用跳表不用红黑树</strong>（查询单个数据时间复杂度一样但是如下）：<br>1.在做范围查找的时候，红黑树树比skiplist操作要复杂。<br>2.平衡树的插入和删除操作会引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。<br>3.跳表的实现相较于红黑树更加简洁。</p><p><strong>一条SQL语句执行的很慢原因</strong>：先分成俩种情况<br>偶尔很慢：1.数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘，此时其他操作需要等待<br>2.执行的时候，遇到锁，如表锁、行锁。<br>一直很慢：1.没有用上索引，例如该字段没有索引或者对索引字段进行运算、函数操作导致无法用索引。<br>2.数据库选错了索引，由于统计的失误，导致系统没有走索引，而是走了全表扫描</p><p><strong>TCP粘包是什么</strong>:    TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾</p><p><strong>造成粘包原因：</strong>发送方，TCP默认使用Nagle算法 1.将多次间隔较小、数据量小的数据，合并成一个大的数据块，然后进行封包。2.TCP面向字节流，无消息边界。解决方式： 1.数据带固定的开始符和结束符 2.数据长度固定，定长发送</p><p><strong>TCP如何保证数据的顺序化传输</strong>：1.为了保证数据包的可靠传递，发送方必须把已发送的数据包保留在缓冲区；<br>2.并为每个已发送的数据包启动一个超时定时器；<br>3.如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则释放该数据包占用的缓冲区;<br>4.否则，重传该数据包，直到收到应答或重传次数超过规定的最大次数为止。<br>5.接收方收到数据包后，先进行CRC校验，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。</p><p><strong>索引为什么能加快查询效率</strong>：索引通过事先排好序，从而在查找时可以应用二分查找等高效率的算法。</p><p><strong>AQS</strong>就是基于双向队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列尾部，等待被唤醒。AQS是自旋锁：在等待唤醒的时候，经常会使用自旋的方式，不停地尝试获取锁，直到被其他线程获取成功</p><p><strong>Runnable和Callable的区别？</strong>：Runnable接口中的run()方法无返回值，只是纯粹的执行run方法，而Callable接口中的call()方法是有返回值的，是一个泛型，和Future、FutureTask配合可以用来获取异步执行的结果。</p><p><strong>线程和进程的区别</strong>：<strong>进程</strong>是一个程序在处理机顺序执行所发生的活动，是程序运行和资源分配的基本单位，程序运行就会为之创建一个进程，并且为它分配资源，然后把该进程放入进程就绪队列，进程调度器选中的时候就会为它分配 CPU 时间，程序开始真正运行 。（Linux 通过 fork 函数创建进程）      <strong>线程</strong>是程序执行的最小单位，它是 CPU 调度和分派的基本单位，一个进程可以由多个线程组成，线程间共享进程的所有资源，同样多个线程也可以并发操作，每个进程有自己的堆栈和局部变量。                <strong>协程</strong>，是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制，不会像线程切换那样消耗资源，协程在子程序内部是可中断的，可以在适当的时候再返回来接着执行。比较有争议的是协程到底需要不需要加锁，视具体情况而言。</p><p><strong>程序</strong>： 静态的代码和数据集合；不能并发； 不具有唯一标识；        <strong>进程</strong>： 动态的程序执行过程； 可并发； 在内存中具有唯一标识；</p><p><strong>count(1)和count(*)基本没有差别</strong>！都包含null的记录，count(字段) 则不包含null的记录。</p><p><strong>数据量大如何传输？</strong>分片，如何分片，就是计算偏位移，最低8字节倍数，MTU默认1500字节，分段传输。如何再组合起来？接收方在第一个分片到达，会分配一个存储缓冲区，并启动一个计时器(超时就丢弃那种)，当数据报后续分片到达，在缓冲区中根据偏移量再组合到一起就OK了，和原来一样，哈哈。</p><p><strong>长连接</strong>指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。<strong>短连接</strong>指每发送一次数据才建立一次连接，发送完就关闭。长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况例如：数据库的连接用长连接。http请求一般是短连接，如果高并发下都是长连接，那么服务器会耗费很多的资源。</p><p><strong>三种进程调度算法：</strong>优先调度算法：先来先服务调度算法，短作业优先级调度算法        高优先权优先调度算法：非抢占式优先权算法，抢占式优先权算法，高响应比优先调度算法，        基于时间片的轮转调度算法：时间片轮转调度算法，多级反馈队列调度算法</p><p><strong>分页和分段的区别：</strong>页是信息的物理单位，分页是为了方便管理内存，对用户来说是透明的，段是信息的逻辑单位，是程序逻辑的要求，对用户来说，是可见的是不透明的。页大小固定，段大小不固定。从用户角度看，分页的地址空间是一维的，分段的地址空间是二维的。</p><p>在地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生<strong>缺页中断</strong>。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须从内存中移出一个页面，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做<strong>页面置换算法</strong>。 FIFO ，LRU。</p><p>1、kafka利用zookeeper去选举出controller；2、kafka通过controller选指定出leader和follower，而无需通过zookeeper了。</p><p><strong>为什么要有用户态和内核态</strong>？由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络。</p><p><strong>注释是啥？</strong>注释是一个接口，底层是Java通过JDK动态代理的方式生成了一个实现了”注解对应接口”的实例。</p><p><strong>如何缩短DNS解析时间：</strong>1.增加域名的缓存命中率，就是增大TTL（一条域名解析记录在DNS的存留时间）和提高网站访问量        2.选择更快的本地 DNS Server 例如 Google DNS         3.选择更快的域名 Name Server</p><p><strong>host：</strong>没有扩展名的系统文件，加快域名解析，方便局域网用户，屏蔽一些网站，顺利连接系统，虚拟域名，Hosts的IP解析优先级比DNS要高</p><p><strong>XSS（跨域脚本攻击）</strong>：一般分为两类，反射型和存储型。反射型xss指的是客户端的不安全输入而引起的攻击，存储型xss指的提交带有恶意脚本内容的数据到服务器上。手段：盗用cookie，植入Flash获得更高权限等等     防御：特征防御，代码修改防御，不信任用户提交任何内容，cookie防盗，Session标记。</p><p><strong>fork函数</strong>被调用一次但返回两次。两次返回的唯一区别是子进程中返回0值而父进程中返回子进程ID。</p><p><strong>浅复制</strong>：浅复制仅仅复制所考虑的对象，而不复制它所引用的对象。<strong>深复制</strong>：深复制把复制的对象所引用的对象都复制了一遍。</p><p><strong>B树和B+树的区别</strong></p><p>1）B树的每个结点都存储了key和data，B+树的data存储在叶子节点上。<br> 节点不存储data，这样一个节点就可以存储更多的key。可以使得树更矮，所以IO操作次数更少。<br> 2）B+树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录<br> 由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。</p><p><strong>慢查询</strong>是指执行时间超过慢查询时间的sql语句show variables like ‘long_query_time’;    <strong>Explain</strong>找到慢查询后，我们需要使用Explain来分析执行慢的原因，分析显示信息有：id,select_type,type</p><p><strong>ps命令</strong>——查看静态的进程统计信息    ps aux | grep bash结合管道操作和grep命令进行过滤，用于查询某一个进程的信息。        <strong>top命令</strong>——查看进程动态信息，CPU负载情况    top -d(每隔2秒显示所有进程的资源占用情况)    默认5秒     <strong>top-load average</strong>查看系统的负载情况                        <strong>rm删除文件</strong>：-r 递归删除文件夹下所有文件， -f不提示直接删除        <strong>iostat</strong>——Linux查看IO    查看<strong>Linux</strong>内核版本命令:    1.cat     2.uname -a                <strong>kill -9</strong>：立即杀死该进程kill**：释放资源后再杀死</p><p><strong>QPS</strong>：是一台服务器每秒能够相应的查询次数，<strong>TPS</strong>   事务数/秒，客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。</p><p><strong>分布式数据库？</strong>：支持持久化存储的分布式存储系统；着重计算的分布式计算框架；着重计算的分布式计算框架；Redis ，ES，mongodb</p><p><strong>Redis事务：</strong>Redis的事务实质上是<strong>命令的集合</strong>，在一个事务中要么所有命令都被执行，要么所有事物都不执行。 分为三步，<strong>MULTI</strong> 开始一个事务，放入一个队列中，<strong>EXEC</strong>执行一个事务。        需要注意的是，Redis不提供回滚，一个事务中的<strong>命令出现错误</strong>，那么<strong>所有的命令都不会执行</strong>；一个事务中出现<strong>运行错误</strong>，那么<strong>正确的命令会被执行</strong>。    利用WATCH命令来实现原子性。</p><p><strong>ArrayList和LinkList</strong>，同样查找, 时间复杂度都是O(N), 但是数组要比链表快，因为数组是连续存储的，链表是散列存储的。数组随机访问性强（通过下标进行快速定位），所以数组的查询比链表要快，链表不能随机查找，必须从第一个开始遍历，查找效率低。ArrayList新增和删除慢，因为ArrayList要移动数据。</p><p><strong>如何避免死锁</strong>：加锁顺序，加锁时限，死锁检测。<strong>死锁</strong>是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。<strong>4个必要条件：</strong>互斥条件，请求与保持条件，不可剥夺条件，循环等待条件</p><p><strong>数据库的乐观锁如何实现：</strong>给表加一个<strong>版本号</strong>或<strong>时间戳</strong>字段，当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断当前版本信息与第一次取出来的版本值大小，相等则予以更新，否则认为过期，拒绝更新。</p><p><strong>Java 泛型擦除</strong>，修饰成员变量等类结构相关的泛型不会被擦除，容器类泛型会被擦除</p><p><strong>AOF阻塞：</strong>后台线程每秒对AOF文件做同步操作。当硬盘压力过大时，fsync操作需要等待，直到写入完成。如果主线程发现距离上一次的fsync（将内存已修改数据同步到存储结构）成功超过2秒，为了数据安全性它会阻塞直到后台线程执行fsync操作完成。这种阻塞行为主要是硬盘压力引起。</p><p>一个<strong>Native Method</strong>就是一个java调用非java代码的接口。</p><p>为啥<strong>JDK8之前的接口</strong>不加default方法？多接口有相同的方法时会冲突，1.8之前接口都是抽象方法，所有的子类都必须重写所有的抽象方法，而8之后的接口同名方法如果都重写了，就会造成冲突。</p><p><strong>Redis快照底层实现</strong>：Copy-On-Write，写入时复制思想。CopyOnWriteArrayList，是一个写入时复制的容器，它是如何工作的呢？简单来说，就是平时查询的时候，都不需要加锁，随便访问，只有在写入/删除的时候，才会从原来的数据复制一个副本出来，然后修改这个副本，最后把原数据替换成当前的副本。修改操作的同时，读操作不会被阻塞，而是继续读取旧的数据。这点要跟读写锁区分一下。</p><p><strong>中断处理中cpu现场环境存储在哪里？</strong>广义上是指当前操作的环境包括寄存器中的所有数据（AX，BX，CX，DX，SP，BP，SI，DI，IP），全部入内存。狭义上是指当前的指令指针IP的位置。</p><p><strong>用堆外内存的情况：</strong>1.和nio有关的一些接口需要堆外内存，操作系统直接把数据写到堆外内存，不需要内核先复制，用户再复制一份   2.java堆自动内存管理能力无法为业务专门调优的时候，就需要堆外了开辟方法：DirectBuffer，用JNI（Java Native Interface）写java的c的扩展</p><p><strong>双亲委托机制的意义 — 防止内存中出现多份同样的字节码</strong></p><p>mybatis是如何做到<strong>防止sql注入</strong>的：<strong>#</strong>执行时，会直接使用编译好的SQL，空位用占位符“?”替代。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。                #将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号，和$的区别就在此。</p><p><strong>大小端的区别</strong>在于数据在内存中的存放字节序不同,大端时一个4字节的数据存放在内存中时,高字节存在低地址,低字节存在高地址;小端时高字节存在高地址,低字节存在低地址。<strong>大小端的用处：</strong>我们知道<strong>网络上的数据</strong>都是以大端数据模式进行交互的，而<strong>我们的主机</strong>大多数是以小端数据模式进行处理，它们如果不进行转换的话，势必会引起数据混乱。</p><p><strong>栈溢出：</strong>方法执行创建的栈帧超过了栈的深度，最有可能的就是方法递归调用产生这种结果。通过用参数 -Xss 去调整JVM栈的大小。</p><p><strong>二叉树查找</strong>时间复杂度如果是平衡的，其查找效率为<strong>O(Log2n)</strong>，近似于折半查找。如果完全不平衡，查找效率为O(n)。</p><p><strong>为什么不同引擎锁的粒度不一样？</strong>InnoDB之所以可以锁行，是因为<strong>聚簇索引</strong>，是因为Innodb的主索引结构上，既存储了主键值，又直接存储了行数据，可以方便的锁住行数据，而MyIsam索引指向另一片数据文件，没有办法精确锁住数据段，因为是<strong>非聚簇索引</strong>。</p><p><strong>线程安全</strong>就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。</p><p><strong>Object类有哪些方法</strong>：clone方法，getClass方法，toString方法，finalize方法，equals方法，hashCode方法，wait方法，notify方法，notifyAll方法</p><p><strong>建索引：</strong>（1）CREATE INDEX indexName ON tableName(username(length))；                            （2）ALTER table tableName ADD UNIQUE [indexName] (username(length))</p><p>不借助第三变量，转换俩数值，a = a + b;//8        b = a - b;//3            a = a - b;//5</p><p><strong>redis故障转移过程</strong>：1.检查从节点成为主节点的资格    2.准备选举时间，断线时间越短，丢失数据越少，优先获取选举资格    3.选举投票：主节点获取资格，向其他从节点发起请求，然后替换成主节点    4.替换主节点，投票成功后，向全体从节点广播pong消息，表示已替换主节点。</p><p>一台机器最多能使用的端口也只有65535个，1024以下是系统保留的，从1024-65535是用户使用的，但是一台机器最多只能利用<strong>28232</strong>个端口。</p><p>0-4先扩大五倍，变成0，5，10，15，20，随机产生0-20区间数字，即大于20重新生成，结果对3求商即可。</p><p><strong>可重入锁</strong>毕竟是API这个级别的，后续的性能优化空间很小。synchronized则是JVM直接支持的，JVM能够在运行时作出相应的优化措施：锁粗化、锁消除、锁自旋等等。这就使得synchronized能够随着JDK版本的升级而不改动代码的前提下获得性能上的提升。</p><p><strong>泛型</strong>，指定集合内元素的类型，也就是说，在编译阶段使用泛型，运行阶段取消泛型，即泛型擦除。 擦除是将泛型类型以其父类代替，如String 变成了Object等。其实在使用的时候还是进行带强制类型的转化，只不过这是比较安全的转换，因为在编译阶段已经确保了数据的一致性。</p><p>当我们使用<strong>shutdownNow方法</strong>关闭线程池时，一定要对任务里进行异常捕获。当我们使用<strong>shuwdown方法</strong>关闭线程池时，一定要确保任务里不会有永久阻塞等待的逻辑，否则线程池就关闭不了。最后，一定要记得，shutdownNow和shuwdown调用完，线程池并不是立马就关闭了，要想等待线程池关闭，还需调用awaitTermination方法来阻塞等待。</p><p>AOF文件太大解决方案：<strong>AOF重写</strong>方案，随着AOF文件越来越大，里面会有大部分是重复命令或者可以合并的命令，redis主进程fork一个子进程，子进程根据当前内存的数据，构建一个新的日志，写入一个新的AOF文件中。</p><p><strong>linux查看文件中的某几行</strong>，用head&amp;tail命令，使用 ls -l 可以查看一个目录下文件的详细的相关信息，ls -a 查看当前目录下的所有文件        <strong>tail -n 10 log</strong>查看日志尾部后10行，<strong>tail -n +10 log</strong>查看日志10行之后所有的<strong>head -n 10 log</strong>查看日志首部前10行    <strong>head -n -10 log</strong>查看日志除了最后10行所有的    如何查看系统的启动时间    <strong>uptime</strong></p><p>一个<strong>数组</strong>既可以存放基本类型值（如int,char,…)，也可以存放对象的引用（比如指针）。</p><p>事实上现在都用虚拟内存的方式，把程序分段加载到虚拟内存中，再把内存分页，通过段表、页表的形式来映射程序在内存中的位置。</p><p><strong>IOC容器加载过程：</strong>1.刷新容器，进行预处理。2.将配置信息解析，注册到BeanFactory。3.设置bean的类加载器4.bean加载注册完成后，初始化前可以做些一些操作，例如修改bean的scope为单例或者多例。5.初始化当前 ApplicationContext 的事件广播器。6.初始化所有的bean。 7.广播applicationcontext初始化完成。</p><p><strong>Collections.shuffle（）</strong>：随机打乱数组中元素的顺序.</p><p>从根节点到任意节点最多经历2lg(n+1)步，因此红黑树的时间复杂度为O(lgn).</p><p>*<em>为什么用SpringMVC： *</em> springmvc作为spring的一部分，spring可提供一些功能，清晰的角色分配，dispatcherServlet,handlerMapping,HandlerAdapter,ViewResolver</p><p><strong>linux是怎么创建进程和线程的：</strong>fork()是将父进程的全部资源复制给了子进程。而线程的clone()只是复制了一小部分必要的资源。</p><p><strong>GBK编码</strong>：是指中国的中文字符，<strong>UTF-8编码</strong>：它是一种全国家通过的一种编码</p><p><strong>孤儿进程：</strong>一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。<strong>僵尸进程：</strong>一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</p><p>利用<strong>select * for update</strong> 可以锁表/锁行。自然锁表的压力远大于锁行。所以我们采用锁行。当没有明确指定的时候锁表。</p><p>线程虽然有自己的堆栈和局部变量，但线程没有单独的地址空间，<strong>一个线程死掉就等于整个进程死掉</strong></p><p>已知有100个元素，那么<strong>hashmap默认容量</strong>应该是多少？100/0.75=134 所以取2的指数幂256。    </p><p>我们的InnoDB存储引擎也有自己的最小储存单元——<strong>页（Page）</strong>，一个页的大小是16K。</p><p><strong>Mybatis缓存：</strong>一级缓存是<strong>SqlSession级别</strong>的缓存。在操作数据库时需要构造 sqlSession对象，在对象中有一个(内存区域)数据结构（HashMap）用于存储缓存数据。    二级缓存：<strong>mapper级别的缓存</strong>，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession去操作数据库得到数据会存在二级缓存区域，多个SqlSession可以共用二级缓存，二级缓存是多个SqlSession共享的。</p><p><strong>TCP的序号</strong>是：当前所携带的数据的第一个字节的顺序号（如：已发出了100个字节，现在发送下一个报文，假设每个报文携带的数据为100字节，则这个报文的头结构中的序号是100【注：<a href="https://www.baidu.com/s?wd=从0开始&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao" target="_blank" rel="noopener">从0开始</a>编号】）。以便于接收方能按顺序接受数据，提供了数据可靠性。<br><strong>确认序号</strong>是：接收端期望接收的下一个报文的序号，如上例中那个报文已被正确接收，则接收端会发送一个ACK=1且确认序号=200的应答报文给发送方。</p><p><strong>虚拟内存的大小有什么来决定：</strong>由CPU的寻址能力和你虚拟内存页面文件所在盘符的硬盘剩余空间决定的．比如说，32位的CPU最多支持到2G的内存，应该是虚拟内存也是这么大．如果页面文件放在D盘，剩余空间是200M，那么也就是200M</p><p><strong>count++不是原子操作</strong>，是3个原子操作组合    1.读取主存中的count值，赋值给一个局部成员变量tmp    2.tmp+1    3.将tmp赋值给count</p><p><strong>信号量机制：</strong>即P(sv)和V(sv)（1）P(sv)：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行（2）V(sv)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1.</p><p><strong>SQL第二大薪水</strong>：1.select <strong>max(salary)</strong> as SecondHighestSalary   from Employee where salary not in (select max(salary) from Employee);                    2.SELECT    (SELECT DISTINCT   Salary    FROM    Employee    ORDER BY Salary DESC    LIMIT 1 OFFSET 1) AS SecondHighestSalary    使用临时表能解决null值问题as SecondHighestSalary</p><p>1.<strong>重写</strong>必须继承，<strong>重载</strong>不用。2.重写的方法名，参数数目相同，参数类型兼容，重载的方法名相同，参数列表不同    3.<strong>重写</strong>的方法修饰符大于等于父类的方法，重载和修饰符无关。4.重写不可以抛出父类没有抛出的一般异常，可以抛出运行时异常</p><p><strong>HashMap初始化的四种构造方法</strong>：1.HashMap()，使用默认初始容量16与默认负载因子0.75构造一个空的HashMap。    2.HashMap(int initialCapacity)，传入初始容量，使用默认负载因子        3.HashMap(int initialCapacity, float loadFactor)，传入初始容量和负载因子    4.根据已有的Map接口创建一个元素相同的HashMap</p><p><strong>Spring的设计模式</strong>：工厂模式IOC，代理设计模式AOP，单例模式Sington，观察者模式，适配器模式，模板设计模式jdbcTemplate</p><p><strong>最左前缀匹配原则</strong>，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4  如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。group by，order by 多个字段会用到多个字段的<strong>联合索引</strong>                     </p><p>自己写一个<strong>java.lang.String</strong>在编译期的时候不会报错，但是运行期由于类加载机制，是会报错的，因为类加载器的双亲委派机制和沙箱安全机制，所以自己写的String类不会被加载到内存中，这时调用自己写的String会报错，找不到该方法由于类加载器的双亲委派机制        </p><p><strong>Redis数据类型</strong>：String 类型的值最大能存储 512MB。</p><p><strong>长连接是如何实现的：</strong>发送请求时会携带一个Connection： keep-alive参数，俩端看到该参数就不会关闭连接。</p><p><strong>Memcache与Redis的区别都有哪些？</strong>1.Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，redis可以持久化其数据。            2.memcached所有的值均是简单的字符串，redis支持更为丰富的数据类型 ，提供list，set，zset，hash等数据结构的存储        3.value 值大小不同：Redis 最大可以达到 <strong>512M</strong>；memcache 只有 <strong>1mb</strong>。            4.redis的速度比memcached快很多<br>5.Redis支持数据的备份，即master-slave模式的数据备份。</p><p><strong>TreeSet</strong>是自动排好序的，底层二叉树，<strong>HashSet</strong>无序，<strong>TreeMap</strong>默认按照keys的自然排序排列，底层红黑树。</p><p>select * from student order by subject desc limit 10;</p><p><strong>Spring Boot</strong>缺点：Spring Boot封装层数过多导致的性能问题。    Spring Boot优点：简化配置，简化部署，可以和spring很好结合起来使用。</p><p>重载方法的选择是<strong>静态分派</strong>：依据<strong>参数的静态类型</strong>来判断使用哪个重载方法，而对于重写方法的选择则是<strong>动态分配</strong>：在<strong>运行时</strong>根据实际类型确定方法执行版本</p><p>守护线程应该永远不去访问固有资源，如文件，数据库，因为他会在任何时刻甚至是一个操作的中间发生中断。</p><p>数据库自增id,<strong>当id值大于MAXINT时</strong>，数据库会发生溢出错误，用bigint代替。</p><p>当索引是很长的字符序列时，这个索引将会很占内存，而且会很慢，这时候就会用到<strong>前缀索引</strong>了。所谓的前缀索引就是去索引的前面几个字母作为索引，但是要降低索引的重复率，索引我们还必须要判断前缀索引的重复率。</p><p><strong>Arraylist</strong>扩容为什么要复制一个，不直接复制，因为array具有连续性，要保证连续性才行。<strong>Linkedlist</strong>,如果用get到某一个索引，不是一定非要从头开始遍历，如果在中间位置靠后，是可以从后遍历的。</p>]]></content>
    
    <summary type="html">
    
      针对一些常考知识，简答总结到一起，面试前必看
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>java对象的组成部分</title>
    <link href="http://yoursite.com/2020/02/05/java%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86/"/>
    <id>http://yoursite.com/2020/02/05/java%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86/</id>
    <published>2020-02-05T05:28:38.000Z</published>
    <updated>2020-02-09T13:41:01.563Z</updated>
    
    <content type="html"><![CDATA[<p>对象谁都知道，但对象里面到底有什么，却很少有人去了解，今天我们就来看看对象到底由哪些部分组成</p><p>简单来说：Java对象保存在内存中时，由以下三部分组成：<strong>对象头</strong>，<strong>实例数据</strong>，<strong>对齐填充字节</strong></p><h4 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h4><p>对象头由三部分组成：<strong>Mark Word</strong>，<strong>指向类的指针</strong>，<strong>数组长度</strong>（只有数组对象才有）</p><p><strong>Mark Word</strong>记录了对象和锁有关的信息。</p><p>1.对象没有被当成锁时，Mark Word记录对象的HashCode，锁标志位是01，是否偏向锁那一位是0。</p><p>2.当对象被当做同步锁并有一个<strong>线程A</strong>抢到了锁时，锁标志位还是01，但是否偏向锁那一位改成1，表示进入偏向锁状态</p><p>3.<strong>线程A</strong>再来试图来获得锁时，锁标志位还是01，并发现自己已经得到了偏向锁，所以可以执行同步锁的代码。</p><p>4.当<strong>线程B</strong>试图获得这个锁时，JVM发现同步锁处于偏向状态，但是Mark Word中的线程id记录的不是B，那么线程B会先用CAS操作试图获得锁，这里的获得锁操作是有可能成功的，因为线程A一般不会自动释放偏向锁。如果抢锁成功，就把Mark Word里的线程id改为线程B的id，代表线程B获得了这个偏向锁，可以执行同步锁代码。如果抢锁失败，则继续执行步骤5。</p><p>5.偏向锁状态抢锁失败，代表当前锁有一定的竞争，偏向锁将升级为<strong>轻量级锁</strong>。JVM会在当前线程的线程栈中开辟一块单独的空间，里面保存指向对象锁Mark Word的指针，上述两个保存操作都是CAS操作，如果保存成功，代表线程抢到了同步锁，就把Mark Word中的锁标志位改成00，可以执行同步锁代码。如果保存失败，表示抢锁失败，竞争太激烈，继续执行步骤6</p><p>6.轻量级锁抢锁失败，JVM会使用自旋锁，自旋锁不是一个锁状态，只是代表不断的重试，尝试抢锁。如果抢锁成功则执行同步锁代码，如果失败则继续执行步骤7。</p><p>7.自旋锁重试之后如果抢锁依然失败，同步锁会升级至重量级锁，锁标志位改为10。在这个状态下，未抢到锁的线程都会被阻塞。</p><p><strong>指向类的指针</strong></p><p>该指针在32位JVM中的长度是32bit，在64位JVM中长度是64bit。</p><p>Java对象的类数据保存在方法区。<strong>通过该指针确定该对象是哪个类的实例</strong></p><p><strong>数组长度</strong></p><p>只有数组对象保存了这部分数据。</p><p>该数据在32位和64位JVM中长度都是32bit。</p><h4 id="实例数据"><a href="#实例数据" class="headerlink" title="实例数据"></a>实例数据</h4><p>对象的实例数据就是在java代码中能看到的属性和他们的值。</p><h4 id="对齐填充字节"><a href="#对齐填充字节" class="headerlink" title="对齐填充字节"></a>对齐填充字节</h4><p>JVM要求java的对象占的内存大小应该是8bit的倍数，所以后面有几个字节用于把对象的大小补齐至8bit的倍数，没有特别的功能。</p><p>原文链接：<a href="https://blog.csdn.net/lkforce/article/details/81128115" target="_blank" rel="noopener">https://blog.csdn.net/lkforce/article/details/81128115</a></p>]]></content>
    
    <summary type="html">
    
      对象头和对象组成详解
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>聚集索引和非聚集索引</title>
    <link href="http://yoursite.com/2020/02/04/%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95%E5%92%8C%E9%9D%9E%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/2020/02/04/%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95%E5%92%8C%E9%9D%9E%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95/</id>
    <published>2020-02-04T05:16:43.000Z</published>
    <updated>2020-02-14T14:14:03.333Z</updated>
    
    <content type="html"><![CDATA[<h4 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a><strong>聚集索引</strong></h4><p>聚集索引存储记录是物理上连续存在，且它的<strong>物理顺序</strong>与列值（一般是主键的那一列）的<strong>逻辑顺序</strong>相同，一个表中只能拥有一个聚集索引。例如第一行地址为01，id值1，第二行地址为02，id为2.</p><p>我们可以看出，聚集索引和id的关联很大，如果我们查询id比较靠后的数据，那么这行数据的地址在磁盘中的物理地址也会比较靠后。</p><p>在MySQL中<strong>主键就是聚集索引</strong>，SQL Sever默认主键为聚集索引，也可以指定为非聚集索引</p><p><strong>那么主键和聚集索引区别是什么？</strong></p><blockquote><p>如果在创建表时没有显式地定义主键,则InnoDB存储引擎会按如下方式选择或创建主键:</p><p>1 首先判断表中是否有非空的唯一索引,如果有,则该列即为主键.</p><p>2 如果不符合上述条件,InnoDB存储引擎自动创建一个6字节大小的指针.</p></blockquote><p>其实聚集索引可以创建在<strong>任何一列</strong>，但我们一般不会这么做，因为性能非常差。主键不可以有重复数据，那么聚集索引呢？</p><p>其实聚集索引是有<strong>唯一性约束</strong>的，那为什么可以在任何列创建呢？因为必要时，数据库引擎 将向行自动添加一个 uniqueifier 值，使每个键唯一。此列和列值供内部使用，用户不能查看或访问。</p><p><strong>说了半天，聚集索引到底是个啥？</strong></p><p>索引底层大家都知道是B+树，而<strong>聚集索引的叶子节点就是对应的数据节点</strong>，可以直接获取对应列的数据，查询非常高效。</p><h4 id="非聚集索引"><a href="#非聚集索引" class="headerlink" title="非聚集索引"></a><strong>非聚集索引</strong></h4><p><strong>磁盘上行的物理存储顺序与索引列的逻辑顺序不同</strong>，一个表中可以拥有多个非聚集索引。</p><p>除了聚集索引以外的索引都是非聚集索引，只是人们想细分一下非聚集索引，分成普通索引，唯一索引，全文索引。</p><p><strong>非聚集索引和聚集索引的区别？</strong></p><p>最根本区别就是<strong>非聚集索引的叶子节点仍然是索引节点</strong>，但它有一个指向最终数据的指针，所以它需要进行第二次的查询，查询对应行数据。</p><p>聚集索引：可以帮助把很大的范围，迅速减小范围，从小范围一个一个找。<strong>查询1次所以速度快</strong></p><p>非聚集索引：把一个很大的范围，转换成一个小的地图，从地图上找到位置，再直接过去找。<strong>查询2次速度慢，但是修改相较于聚集索引快</strong></p><p><strong>在主键创建聚集索引查询快，还是创建非聚集索引查询快呢？</strong></p><p>答：<strong>非聚集索引快</strong>。因为要在主键上创建聚集索引，那么就要<strong>保证主键的唯一性</strong>，我们就需要遍历所有数据的节点判断主键是否唯一。而非聚集索引本身叶子节点放的都是主键，我们只需要遍历索引页就行了，不用去查找数据（索引的存储空间比实际数据要少）。这样减少了很多的IO消耗，所有快。</p><p><strong>选择</strong>：如果是返回范围的数据，那么选择聚集索引。如果是频繁的修改索引列，那么应该选择非聚集索引。</p>]]></content>
    
    <summary type="html">
    
      俩种索引的区分和概念
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>基于lucene的elasticsearch</title>
    <link href="http://yoursite.com/2020/02/03/%E5%9F%BA%E4%BA%8Elucene%E7%9A%84elasticsearch/"/>
    <id>http://yoursite.com/2020/02/03/%E5%9F%BA%E4%BA%8Elucene%E7%9A%84elasticsearch/</id>
    <published>2020-02-03T06:16:00.000Z</published>
    <updated>2020-04-23T15:21:36.807Z</updated>
    
    <content type="html"><![CDATA[<h3 id="lucene"><a href="#lucene" class="headerlink" title="lucene"></a>lucene</h3><p>首先，elasticsearch（简称ES）是基于lucene的，lucene是什么？lucene 是最先进、功能最强大的搜索库，其实就是一个jar包，包含了封装好的各种建立倒排索引的算法代码，如果直接基于 lucene 开发，非常复杂，所以我们一般直接就调用lucene 的 api 去开发就可以了。</p><p><strong>搜索引擎原理</strong>：爬取内容，进行分词，建立反向索引也叫倒排索引。</p><p><strong>倒排索引</strong>是什么？传统正向索引，在文章中找词，而倒排索引是从关键词出发，找到对应的文章。</p><p>倒排底层实现基于<strong>FST</strong>,优点空间占用小，对单词前缀和后缀重复利用，查询快。</p><p><strong>Elasticsearch</strong></p><p>而elasticsearch 就是基于 lucene，隐藏了 lucene 的复杂性，提供了简单易用的 restful api 接口，是一个存储海量数据的分布式搜索引擎。</p><p>为什么要有ES，因为模糊查询会放弃索引，会导致全表扫描，大数据量下效率低，而我们可以把经常查询的字段放入ES中，可以提高查询速度。</p><p><strong>基本结构</strong>：</p><p>索引（index）:类似一个数据库，可以是商品索引，每个索引里可以有一个或者多个 type。</p><p>类型（type）：类似数据的一个表。可以是家用商品类型，电器商品类型，一个type包含多条document，用mapping定义type表结构类型例如哪些字段，字段是哪些类型。</p><p>文档（document）：类中表的一条数据，es 中最小的数据单元,可以是一条商品数据、一条订单数据，通常用 json 数据结构来表示。每个 document 有多个 field，每个 field 就代表了这个 document 中的一个字段的值。</p><p><strong>分布式原理</strong>：</p><p>Elasticsearch 会对数据进行切分(shard)，同时每一个分片会保存多个副本(replica ),为了保证分布式环境下的高可用。</p><p>并且同样基于maste-slave架构，在 Elasticsearch 中，节点是对等的，节点间会通过自己的一些规则选取集群的 Master，Master 会负责集群状态信息的改变，并同步给其他节点。</p><p>注意，只有建立索引和类型需要经过 Master，数据的写入有一个简单的 Routing 规则，可以 Route 到集群中的任意节点，所以数据写入压力是分散在整个集群的。</p><p> Elasticsearch 搭建 ELK 系统，也就是日志分析系统。其中 E 就是 Elasticsearch，L 是 Logstash，是一个日志收集系统，K 是 Kibana，是一个数据可视化平台。</p><p>keyword和text字段区别：keyword直接建立反向索引，text先分词再建立反向索引</p><p><strong>缺点：</strong>：没有用户验证和权限控制，没有事务的概念，不支持回滚，误删不能恢复，需要java环境.</p><p><strong>优点</strong>：将你的文档分割到不同容器或者分片中，可以存在单个节点或多个节点复制每个分片提供数据备份，防止硬件问题导致数据丢失。</p><p><strong>存取方式：</strong>gateway ，ES是先把索引的内容保存到内存之中，当内存不够时再把索引持久化到硬盘中，同时它还有一个队列，是在系统空闲时自动把索引写到硬盘中。</p><p><strong>面试题</strong></p><p>写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是<strong>随机轮询算法</strong>。</p><p><strong>搜索过程</strong>：客户端发送请求到一个协调节点，协调节点将搜索请求转发到所有的 shard 对应的 <code>primary shard</code> 或 <code>replica shard</code>，每个 shard 将<strong>文档的ID和排序值</strong>返回给协调节点，然后协调节点根据这些ID去各个节点拉取document 数据返回给客户端。</p><p>如何实现master选举：1.确认候选主节点数达标         2.比较：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值会主节点。</p><p>性能优化：1.es 的搜索引擎严重依赖于底层的 <strong>filesystem cache</strong>，你如果给 filesystem cache 更多的内存，尽量让内存可以容纳所有的索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。            2.<strong>数据预热</strong>，每隔一段时间，就访问一下，让数据进入 filesystem cache 里面去。               3.<strong>冷热分离</strong>，将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引</p>]]></content>
    
    <summary type="html">
    
      elasticsearch到底是怎么样的搜索啊
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Get和Post的区别</title>
    <link href="http://yoursite.com/2020/02/02/Get%E5%92%8CPost%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2020/02/02/Get%E5%92%8CPost%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-02-02T12:54:35.000Z</published>
    <updated>2020-03-23T05:29:11.909Z</updated>
    
    <content type="html"><![CDATA[<p><strong>不同：</strong></p><p>1.get参数通过URL传递，post放在Request body中，所以相对来说post更加安全。</p><p>2.get传递数据是通过URL进行传递，对传递的数据长度是受到URL大小的限制，URL最大长度是2048个字符。post没有长度限制，可发送更多数据</p><p>3.get后退不会有影响，post后退会重新进行提交</p><p>4.get产生一个TCP数据包（header和data一起发送），post产生两个TCP数据包（先发送header，再发送data）。也就是get请求一次，post俩次（不是都俩次，火狐听说就一次）。get效率高，post传输慢。</p><p>5.get请求可以被缓存，post不可以被缓存</p><p>6.get请求只支持URL编码，post支持多种编码方式</p><p>7.get只支持ASCII字符，post没有字符类型限制</p><p>8.get请求参数会留在历史记录中，post请求不会留在历史记录</p><p>9.get是幂等的，post是不幂等的（幂等：对同一URL的多个请求应该返回同样的结果，例如发送一个请求，长时间得不到回应就会重新再发生一个，然后接受方就得到了俩个相同的请求，幂等性就是决定了第二个请求是否有效。实例：用户在APP上连续点击了多次提交订单，后台应该只产生一个订单）</p><p><strong>相同：</strong></p><p>GET和POST是什么？HTTP协议中的两种发送请求的方法。</p><p> HTTP是什么？HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。</p><p>GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。</p>]]></content>
    
    <summary type="html">
    
      get和post,问出来必须知道的几个点
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>MD5！！</title>
    <link href="http://yoursite.com/2020/02/02/MD5%E6%98%AF%E4%B8%AA%E5%95%A5%EF%BC%9F/"/>
    <id>http://yoursite.com/2020/02/02/MD5%E6%98%AF%E4%B8%AA%E5%95%A5%EF%BC%9F/</id>
    <published>2020-02-02T05:23:56.000Z</published>
    <updated>2020-02-09T14:25:25.472Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>今天写简历的时候回想起自己所写项目的难点，突然想起了MD5加密，当初的难点虽然非常多，但是这个尤为记忆深刻！现在还记得，当初找到了一个MD5加密工具类，然后给自己的密码加了密，数据库中的密码就变成了类似b8c37e33defde51cf91e1e03e51657da这样的东西。当时就觉的很厉害也没注意，没想到更厉害的还在后面，我不小心把密码忘了，再登录已经登不上去，没办法只能去改数据库的密码了，没想到改了还是登不上去，这就叫我很纳闷了，还能这样的，今天就来看看他为什么。</p><h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p>首先，MD5 是摘要算法而不是加密算法，属于Hash算法一代，是一种单向加密算法，可以将输入的信息加密转换为128位固定长度的散列值，用于检验数据传输过程中的完整性。一般配合加盐来使用。</p><p><strong>摘要算法</strong>是单向的，即明文可以通过摘要算法生成摘要结果，但反之则不能通过摘要结果还原成明文（<strong>意思就是不可逆，不能解密</strong>）。</p><p>而<strong>加密算法</strong>是双向的，即可以从明文通过加密算法生成密文，反之也可以通过解密算法将密文还原成明文。</p><p>加密算法，可以分可逆加密，不可逆加密，可逆加密又分为对称加密与非对称加密（RSA公钥加密算法，公钥是可发布的供任何人使用，私钥则为自己所有，供解密之用。）</p><p><strong>摘要算法主要用来检查明文是否发生过变动，而加密算法则用来传递不能让第三方知晓的内容。</strong></p>]]></content>
    
    <summary type="html">
    
      MD5都听说过，如何大致理解它，今天就来说说
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Redis和mysql的数据一致性</title>
    <link href="http://yoursite.com/2020/02/01/Redis%E5%92%8Cmysql%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <id>http://yoursite.com/2020/02/01/Redis%E5%92%8Cmysql%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/</id>
    <published>2020-02-01T15:05:20.000Z</published>
    <updated>2020-02-15T05:25:41.203Z</updated>
    
    <content type="html"><![CDATA[<h3 id="利用Redis缓冲读数据的流程为："><a href="#利用Redis缓冲读数据的流程为：" class="headerlink" title="利用Redis缓冲读数据的流程为："></a><strong>利用Redis缓冲读数据的流程为：</strong></h3><p>开始读，判断缓冲中是否有数据，有则返回给客户端，没有的话就会去数据库中查询，如果还没有就返回没有，如果有的话就会写入缓冲中，再返回客户端。</p><p>一般业务操作都是该流程，读的话可以看出不会出现太大问题，但如果有数据的更新呢？那么就会产生一些问题了。</p><h3 id="可能会出现的问题："><a href="#可能会出现的问题：" class="headerlink" title="可能会出现的问题："></a><strong>可能会出现的问题：</strong></h3><p>更新数据的时候，先更新数据库，然后要删除缓存旧的数据，但是没有删除成功，此时数据库和缓存的数据就发生了不一致。</p><p>改进：要求先删除缓存数据成功后，再更新数据库，这样保证数据一致性。</p><p>但还是会有问题：删除缓存数据成功后，更新数据库的操作还没执行完的时候，另一个线程就来读数据，此时缓存为空，去数据库查找，此时数据库的数据还是没更新前的，读取到然后传给缓存。这时候数据库成功更新了数据，接下来就知道了，数据库和缓存的数据不一致了。</p><h3 id="那么到底如何解决一致性问题呢？"><a href="#那么到底如何解决一致性问题呢？" class="headerlink" title="那么到底如何解决一致性问题呢？"></a><strong>那么到底如何解决一致性问题呢？</strong></h3><p>从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。我们接下来考虑的都不是设置过期时间的方法。</p><p><strong>1.采用延时双删策略</strong></p><p>先删除缓存，再写数据库，休眠500毫秒，再次删除缓存。这样可以确保另一个线程读请求结束，写请求可以删除读请求造成的缓存脏数据（就是上述问题）。休眠时间看自己情况。</p><p><strong>2.异步更新缓存(基于订阅binlog的同步机制)</strong></p><p>binlog二进制日志文件，记录所有增删改的SQL语句，不记录查的语句，因为没有对数据进行修改。</p><p>这样，一旦数据库数据发生更新，就把binlog推给Redis，Redis再根据binlog中的记录，对Redis进行更新。</p><p><strong>MySQL的数据一致性如何保住呢？</strong></p><p>MySQL的主从备份机制也是利用binlog来实现数据一致性，binlog记录推送给Redis的方式可以采用常见的消息队列就行。</p><p>具体实现：1.异步复制，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，会有问题，主库一旦宕机，从库可能收不到数据。</p><p>2.半同步复制，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端，原理就是主库先写入binlog，等到至少一个从库返回确认就可以提交给客户端了。            缺点：有延迟，需要等到，性能下降。</p><p>3.数据库中间件：所有的读写都走数据库中间件，通常情况下，写请求路由到主库，读请求路由到从库，目前常见的中间件，canal，otter（分布式数据库同步系统），都基于数据库增量日志解析。        缺点：成本大</p><p>4.缓存写key法，如果key要发生写操作，记录在cache里，并设置“经验主从同步时间”的cache超时时间,然后修改主数据库。            </p><p>如果key要发生读操作，先看缓存有没有，有相关数据，说明缓存命中，这个key刚发生过写操作，此时需要将<strong>请求路由到主库</strong>读最新的数据。如果缓存没有命中，说明这个key上近期没有发生过写操作，此时<strong>将请求路由到从库</strong>，继续读写分离。                缺点：引入了一个cache组件</p>]]></content>
    
    <summary type="html">
    
      读数据从Redis缓存，那么如何保证Redis和mysql数据是一致的呢。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Git常用的命令！</title>
    <link href="http://yoursite.com/2020/02/01/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%EF%BC%81/"/>
    <id>http://yoursite.com/2020/02/01/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%EF%BC%81/</id>
    <published>2020-02-01T14:53:27.000Z</published>
    <updated>2020-02-19T12:56:43.302Z</updated>
    
    <content type="html"><![CDATA[<p><strong>git add</strong></p><p>git add 是把要传的数据添加到一个仓库或者说是暂存区，意思就是先放在里面，告诉它们我们将要对这些数据进行操作了。</p><p><strong>git commit</strong></p><p>而git commit就是进行操作的第一步，就是将本地修改过的文件提交到<strong>本地库</strong>中。</p><p><strong>git push</strong></p><p>第二步就是git push，将本地库中的最新信息发送给<strong>远程库</strong>，供其他人可见。</p><p><strong>git fetch</strong></p><p>只能更新远程仓库的代码为最新的，本地仓库的代码还未被更新,通常和<strong>git merge</strong> 合并结合来用</p><p><strong>git pull</strong></p><p>将本地仓库和远程仓库都更新到远程的最新版本，相当于git fetch+git merge</p><p>git pull的问题是它把过程的细节都隐藏了起来,出问题很难找到，<strong>可控一点的话推荐使用fetch + merge</strong></p><p><strong>git rebase -i HARD~4</strong></p><p>对最近四次提交进行合并</p>]]></content>
    
    <summary type="html">
    
      Git的add,push,commit
    
    </summary>
    
    
    
  </entry>
  
</feed>
